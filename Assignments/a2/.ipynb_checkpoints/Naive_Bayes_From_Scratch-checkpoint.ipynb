{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E2gUALxIPBws"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anoXZlS6Tj8x"
   },
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIRT9JX5A3g3"
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6tfYRcVtA5bS"
   },
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "\n",
    "  if isinstance(test_size, float):\n",
    "    test_size = round(test_size*len(df))\n",
    "  \n",
    "  indices = df.index.tolist() # random.sample takes list, set, dictionary\n",
    "  test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "  test = df.loc[test_indices]\n",
    "  train = df.drop(test_indices)\n",
    "\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rW28gtRhXGxT"
   },
   "source": [
    "## Calculate Prior Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "B4hlvd5nV44e"
   },
   "outputs": [],
   "source": [
    "def calculate_prior_probabilities(df):\n",
    "\n",
    "  prior_probabilities = df.groupby(by = 'target').apply(lambda x: len(x)/len(df))\n",
    "\n",
    "  return np.log(prior_probabilities).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "42ONfI_tkg-J"
   },
   "outputs": [],
   "source": [
    "# calculate_prior_probabilities(df)\n",
    "\n",
    "# [Prior_probability(setosa), Prior_probability(versicolor), Prior_probability(virginica)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCVsNsy-ZC3c"
   },
   "source": [
    "## Find mean, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zhBDIS0JZCav"
   },
   "outputs": [],
   "source": [
    "def return_statistics(df):\n",
    "\n",
    "  mean = df.groupby(by='target').apply(lambda x: x.mean(axis=0))\n",
    "  variance = df.groupby(by='target').apply(lambda x: x.var(axis=0))\n",
    "\n",
    "  return (mean.values, variance.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z91Ei4T-fwZn"
   },
   "outputs": [],
   "source": [
    "# mean, variance = return_statistics(df)\n",
    "# print(mean)\n",
    "# print(variance)\n",
    "\n",
    "#             s_l  s_w  p_l  p_w\n",
    "# setosa\n",
    "# versicolor\n",
    "# virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWXFmsvcXY9v"
   },
   "source": [
    "## Find Gaussian Probability density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qnu1CIs-XB6-"
   },
   "outputs": [],
   "source": [
    "# P(x=12 | 'setosa')\n",
    "\n",
    "def calculate_probability_density(mean, variance, x):\n",
    "\n",
    "  probability_density = (1 / np.sqrt(2*np.pi*variance) ) * np.exp( (-(x - mean)**2)  / ( 2*variance ) )\n",
    "\n",
    "  return probability_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lgh-OaJ_05Ln"
   },
   "source": [
    "## Posterior Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1ueSjXpbX-3r"
   },
   "outputs": [],
   "source": [
    "def calculate_posterior_probabilities(df_row, mean, variance, n_unique_labels, n_cols):\n",
    "  \n",
    "  posterior_probabilities = []\n",
    "  \n",
    "  # calculate probabilities wrt each label to find max\n",
    "  for i in range(n_unique_labels):\n",
    "    posterior = 0\n",
    "\n",
    "    # for each feature\n",
    "    for j in range(n_cols):\n",
    "      posterior += np.log(calculate_probability_density(mean[i][j], variance[i][j], df_row[j]))\n",
    "    posterior_probabilities.append(posterior)\n",
    "  \n",
    "  return posterior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "loqxsXX1X-yB"
   },
   "outputs": [],
   "source": [
    "# calculate_posterior_probabilities()\n",
    "\n",
    "# [posterior_probability['setosa'], posterior_probability['versicolor'], posterior_probability['virginica']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6LKgZzh00jz"
   },
   "source": [
    "## Fit model on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ma7rUVppX-vt"
   },
   "outputs": [],
   "source": [
    "def NBA_fit(df):\n",
    "\n",
    "  n_cols = len(df.columns)-1\n",
    "  unique_labels = df['target'].unique()\n",
    "  n_unique_labels = len(unique_labels)\n",
    "\n",
    "  mean, variance = return_statistics(df)\n",
    "  prior_probabilities = calculate_prior_probabilities(df) # returns log\n",
    "\n",
    "  return {\n",
    "      'n_cols': n_cols,\n",
    "      'unique_labels': unique_labels,\n",
    "      'n_unique_labels': n_unique_labels,\n",
    "      'mean': mean,\n",
    "      'variance': variance,\n",
    "      'prior_probabilities': prior_probabilities\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Xz3fxWBiX-tL"
   },
   "outputs": [],
   "source": [
    "# nba = NBA_fit(df)\n",
    "\n",
    "# Returns a dictonary containing statistical and other important info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZM6GHJtb0yFz"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4UFBuSjbxiOI"
   },
   "outputs": [],
   "source": [
    "def predict(test_df, nba):\n",
    "\n",
    "  predictions = []\n",
    "  for i in range(len(test_df)):\n",
    "\n",
    "    prior = nba['prior_probabilities']\n",
    "    posterior = calculate_posterior_probabilities(test_df.iloc[i, :-1], nba['mean'], nba['variance'], nba['n_unique_labels'], nba['n_cols'])  # returns log\n",
    "    probabilities = prior + posterior\n",
    "    # one with max prob will be the output \n",
    "    mx_idx = np.argmax(probabilities)\n",
    "\n",
    "    predictions.append(nba['unique_labels'][mx_idx])  # add log values\n",
    "\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FLZrR1joX-rG"
   },
   "outputs": [],
   "source": [
    "# predictions = predict(test_df, nba)\n",
    "\n",
    "# returns label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clVNrTLV809l"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "IEjVfRkhTO_v",
    "outputId": "ab0e92a0-f7af-49cd-bbeb-a0c45da02bba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "\n",
       "   Shell weight  target  \n",
       "0         0.150      15  \n",
       "1         0.070       7  \n",
       "2         0.210       9  \n",
       "3         0.155      10  \n",
       "4         0.055       7  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names =  [\"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole weight\", \n",
    "           \"Shucked weight\", \"Viscera weight\",\"Shell weight\", \"target\"]\n",
    "df = pd.read_csv('abalone.data', header=None, names=names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYAcCD9xIa6P"
   },
   "source": [
    "No null values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzcWouD5AZoX",
    "outputId": "c28acbf3-5797-4d45-cf8c-4f7ccf1f1954"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2d/2_l4krw11ksdxykh0wnch0ww0000gn/T/ipykernel_23017/2404726220.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  mean = df.groupby(by='target').apply(lambda x: x.mean(axis=0))\n",
      "/var/folders/2d/2_l4krw11ksdxykh0wnch0ww0000gn/T/ipykernel_23017/2404726220.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  variance = df.groupby(by='target').apply(lambda x: x.var(axis=0))\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U1'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2d/2_l4krw11ksdxykh0wnch0ww0000gn/T/ipykernel_23017/3037171837.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2d/2_l4krw11ksdxykh0wnch0ww0000gn/T/ipykernel_23017/1195202211.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(test_df, nba)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_posterior_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_unique_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_cols'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# returns log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# one with max prob will be the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2d/2_l4krw11ksdxykh0wnch0ww0000gn/T/ipykernel_23017/3507689843.py\u001b[0m in \u001b[0;36mcalculate_posterior_probabilities\u001b[0;34m(df_row, mean, variance, n_unique_labels, n_cols)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# for each feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mposterior\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_probability_density\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mposterior_probabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2d/2_l4krw11ksdxykh0wnch0ww0000gn/T/ipykernel_23017/3619528148.py\u001b[0m in \u001b[0;36mcalculate_probability_density\u001b[0;34m(mean, variance, x)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_probability_density\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mprobability_density\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvariance\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mprobability_density\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U1'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "train_df, test_df = train_test_split(df, 0.2)\n",
    "\n",
    "# fit model\n",
    "nba = NBA_fit(train_df)\n",
    "\n",
    "# make predictions\n",
    "predictions = predict(test_df, nba)\n",
    "\n",
    "# accuracy\n",
    "accuracy = len(test_df.loc[predictions == test_df['target']])/len(test_df) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-fzSmYcnH1p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sv_IDmtnHzV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Naive_Bayes_From_Scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
